\documentclass[a4paper,10pt]{article}

\usepackage[english]{babel}
\usepackage{graphicx}
\usepackage{float}
\graphicspath{{./figures/}}
\usepackage[colorlinks, linkcolor=black, citecolor=black, urlcolor=black]{hyperref}
\usepackage{geometry}
\geometry{tmargin=2.2cm, bmargin=2cm, lmargin=2cm, rmargin=1.8cm}
\usepackage{todonotes} %Used for the figure placeholders
\usepackage{ifthen}
\newcommand{\subtitle}[1]{\normalsize\normalfont{#1}}

\begin{document}
\newboolean{anonymize}
% Uncomment to create an anonymized version of your report
%\setboolean{anonymize}{true}

\input{titlepage}

\section{Introduction}
This document provides a brief overview of the literature read so far and the chosen approach for predictive web browsing in sequences of web clicks. Section 1 lists the most important takeaways from the literature we have read. Section 2 provides the high level plan we have in mind. Finally, section 3 lists the questions we would like to see answered at the end of our project.

\section{Literature}
We have read literature that may be useful for predicting sequences of web clicks. This literature overview isn't limited to articles on website click sequences, but we also read articles about similar problems like \textit{web recommendation problems} or \textit{unix command line prediction}. This sections describes the most important takeaways from the articles. We structure the takeaways according to fundamental machine learning techniques that may be used for pattern discovery. 

\paragraph{Decision trees} \cite{davison+hirsch} shortly discusses the use of C4.5 for predicting the next unix terminal command. C4.5 is considered as a common, well-studied decision tree learner with excellent performance. However,  the used variant of the algorithm C4.5 showed some drawbacks in this context. Firstly, it returns only the single most likely command. Secondly, it has significant computational overhead. Finally, it does not incrementally update or improve the decision tree upon receiving new information. The article states that their IPAM (Incremental Probabilistic Action Modelling) algorithm outperforms the C4.5 algorithm.

\paragraph{Clustering} \cite{microsoft-smartfavorites} states that clustering of user pages and activities is a common way of classifying users and  personalizing the content or recommendations to be delivered to them. \cite{automatic-personalization} distinguishes transaction and usage clusters. In comparison with traditional collaborative filtering, the article focuses on user transactions of URL references instead of users themselves. Usage clustering computes clusters of URL references based on how often they occur together across user transactions (rather than clustering transactions, themselves). These techniques may be used to cluster the URL references of our click streams. However, the article starts from a company perspective with a lot of data from different users. Techniques proposed in this way may no be as useful in personal plugin application.

\paragraph{Association rule mining} \cite{microsoft-smartfavorites} analyses algorithms for browser  support of predicting either start of web trails and pages associated with trails. Association rule mining is a technique widely used throughout a range of  discovering sequential patters. The article compares predictions based on their own proposed statistical algorithms with association rules. In the latter case on pages associated with trails, the resulting set of rules failed to recommend any pages in 90\% of the times. The reason was that none of the the rules had a left-hand side that matches the current session. They conclude that, while association rules may be helpful for analysis of large-scale web usage data, the logs of individual users do not contain enough repetitive patterns to yield useful rules.

\paragraph{Statistical analysis approach} \cite{microsoft-smartfavorites} proposes two algorithms [PP-Co] and [PP-Seq] for predicting pages associated with trails. The article claims that these algorithms, which take into account statistics about Web trails and constituent pages in the navigation session, outperform  simpler approaches that do not utilize the structure. Another source, \cite{predictive-statistical-models}, lists different predictive statistical models that can be used for content-based learning (this is used when a user's past behaviour is a reliable indicator of the future behaviour). Bayesian networks and Markov models are discussed below.

\paragraph{Bayesian networks} \cite{predictive-statistical-models} proposes Bayesian networks for predictive statistical modelling. Bayesian networks can be used for a variety of predictive modelling tasks. The article states that Bayesian networks provide a compact representation of any probability distribution. Furthermore, these networks explicitly represent causal networks and allow predictions to be made about a number of variables. \cite{search-prediction} discusses Bayesian networks to model web search queries and predict search behaviour. Techniques valid for this problem may also be used for predicting web page sequences.

\paragraph{Markov models} \cite{predictive-statistical-models} proposes Markov models for predictive statistical modelling. Given a number of observed events, the next event is predicted from the probability distribution of the events which have followed these observed events in the past. According to \cite{markov-web-page-accesses} are well suited for modelling and predicting user browsing behaviour on a website. In general, the input for these problems is the sequence of Web pages accessed by a user and the goal is to build Markov models that can be used to predict the Web page that the user will most likely access next. The article states that lower-order Markov models are not very accurate in predicting the user's browsing behavior, since these models do not look far into the past to correctly discriminate the different observed patterns. The article presents techniques for intelligently combining different order Markov models so that the resulting model has a low state-space complexity and, at the same time, retains the coverage and the accuracy of the All-Kth-Order Markov models.



\section{Architecture}

\begin{figure}[H]
\includegraphics[width=1.0\textwidth]{pipeline}
\caption{General architecture of the application.}
\label{pipeline}
\end{figure}

\noindent Figure \ref{pipeline} shows what we plan to implement. First, the gathered data is cleaned and put into a form easily usable by our code. Second, this data is used to build a model. Finally, this model is applied to the current browsing session to predict the pages the user wants to reach. Note that the model is a black box here, which means it can be swapped out easily so we can experiment with and compare different learners.\\

\noindent We now describe a few observations on browsing behaviour that we will try to exploit to predict which page the user wants to see.\\

\noindent When a user is looking for something on the internet, typical web usage goes as follows \cite{krug}: instead of dutifully reading all of the web page and then carefully choosing what to click on, the user looks around feverishly for anything that looks interesting or vaguely resembles what he is looking for. As soon as he finds a half-decent match, he clicks on it, and if it doesn't pan out, he clicks on the Back button (which is by far the most frequently used browser control) and tries again.\\

\noindent We can detect and exploit this behaviour: if for example a user goes from page A to page B, but then immediately goes back to page A, to then click another link, we can assume he didn't want to be on page B, and therefore not predict this page. A related way to exploit temporality is the length the user stays on a page. An assumption we could make (and test) is that staying on a page for a longer time correlates with that page being what the user is looking for. Similarly, if a page is the last page of a browsing session, we could assume that this is a page the user is interested in. 'Being the last page of a browing session' could be detected by the fact that, for a certain period of time, no other user action was recorded after loading this page.\\

\noindent We are planning to start out with a very simple probabilistic model for the learner, where the predicted page is the page that in the past most often followed the current page. We will then extend this to try to predict the last page of the current browsing session, as defined above.\\

\noindent By working with the real data and using our tool ourselves, we will gain a better understanding of how we can improve this first prototype. Existing techniques that look the most promising and that we will try to apply to our problem are Bayesian networks, Markov chains and hidden Markov models (HMM's).\\

\noindent The large collection of classification, regression and clustering techniques in machine learning is not directly applicable to the basic problem here, as can also be seen from the literature study above. We see however one situation where classification or clustering might be applicable: when working with the logs of different users simultaneously. We could then try to divide the users into different classes or clusters and build models for each of these. For the currently active user, we classify him and use the corresponding model, which is then hopefully more useful than a model which is trained on all the users simultaneously.  \\

\noindent We will start coding in Python, because it makes writing readable code easy and because of the large collection of great plugins.\\


\section{Questions}

These are some questions to which we want to find the answers by the end of the project: 

\begin{itemize}
\item Which of the graphical models (Bayesian network, HMM, or something else still) yields the best results, and in what incarnation?
\item Is it correct that classification, regression and clustering are not applicable to the base problem here?
\item Which factors influence the computational and memory cost of preprocessing, learning and evaluating, and how?
\item What is a good metric to compare different learners?
\item What is a good user interface for this tool?
\item Would real users want something like this?
\end{itemize}


\bibliographystyle{apa}
\bibliography{../research}

\end{document}
